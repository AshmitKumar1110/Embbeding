{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBv/aS6UnFKFybwY8NEETF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshmitKumar1110/Embbeding/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMlJ7G8h1hwu",
        "outputId": "ce5f3857-a722-4831-aa16-a258f0008a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from Streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->Streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->Streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->Streamlit) (1.46.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->Streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->Streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->Streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->Streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->Streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->Streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->Streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->Streamlit) (2025.7.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->Streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->Streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->Streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->Streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->Streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->Streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->Streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers faiss-cpu torch pandas\n"
      ],
      "metadata": {
        "id": "BNrC3qTP2Mjf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "st.set_page_config(page_title=\"Code Search & Explanation\", layout=\"centered\")\n",
        "\n",
        "# Title\n",
        "st.title(\"ðŸ” Code Search & Explanation with CodeBERT + CodeT5\")\n",
        "st.markdown(\"Search your codebase using natural language or code snippets, and get explanations with CodeT5.\")\n",
        "\n",
        "# Load CodeBERT model and tokenizer\n",
        "@st.cache_resource\n",
        "def load_codebert():\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "cb_tokenizer, cb_model = load_codebert()\n",
        "\n",
        "# Load CodeT5 summarizer\n",
        "@st.cache_resource\n",
        "def load_codet5():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5-base\")\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "t5_tokenizer, t5_model = load_codet5()\n",
        "\n",
        "# Load FAISS index and code snippets\n",
        "index = faiss.read_index(\"codebert_embeddings.index\")\n",
        "with open(\"code_snippets.json\") as f:\n",
        "    code_snippets = json.load(f)\n",
        "\n",
        "# Embedding function (CodeBERT)\n",
        "def get_embedding(text):\n",
        "    inputs = cb_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = cb_model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "\n",
        "# Search code\n",
        "def search(query, top_k=3):\n",
        "    query_emb = get_embedding(query).reshape(1, -1)\n",
        "    distances, indices = index.search(query_emb, top_k)\n",
        "    results = []\n",
        "    for rank, (idx, dist) in enumerate(zip(indices[0], distances[0]), 1):\n",
        "        results.append({\n",
        "            \"rank\": rank,\n",
        "            \"code\": code_snippets[idx],\n",
        "            \"distance\": float(dist)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Summarize code\n",
        "def summarize_code(code):\n",
        "    input_ids = t5_tokenizer(\"summarize: \" + code, return_tensors=\"pt\", truncation=True).input_ids\n",
        "    with torch.no_grad():\n",
        "        output_ids = t5_model.generate(input_ids, max_length=64, num_beams=4, early_stopping=True)\n",
        "    return t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# UI: Query input\n",
        "query_type = st.selectbox(\"Choose query type:\", [\"Natural Language\", \"Code Snippet\"])\n",
        "query = st.text_area(\"Enter your query:\", height=120)\n",
        "\n",
        "# Perform search\n",
        "if query:\n",
        "    st.info(f\"Searching using {query_type.lower()}...\")\n",
        "    results = search(query, top_k=3)\n",
        "    st.subheader(\"ðŸ”Ž Top Matching Code Snippets:\")\n",
        "    for result in results:\n",
        "        st.code(result[\"code\"], language=\"python\")\n",
        "        st.caption(f\"Rank #{result['rank']} â€¢ Distance: {result['distance']:.4f}\")\n",
        "\n",
        "    # Optional explanation\n",
        "    if query_type == \"Code Snippet\":\n",
        "        if st.button(\"ðŸ§  Explain This Code with CodeT5\"):\n",
        "            explanation = summarize_code(query)\n",
        "            st.subheader(\"ðŸ§  Code Explanation:\")\n",
        "            st.success(explanation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8XNbya11o2Q",
        "outputId": "a818d169-3e7b-4a97-afb1-9e7c88ed1101"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-11 19:52:57.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.296 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.299 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.302 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.347 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.350 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.366 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:52:57.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HdKcM_5f1wiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d5d3feb",
        "outputId": "b0422d7f-0781-4773-d93c-7dcf148b851f"
      },
      "source": [
        "# Create dummy FAISS index and code snippets files for demonstration purposes\n",
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Create a dummy index\n",
        "d = 768  # Dimension of the embeddings (CodeBERT base)\n",
        "nb = 10  # Number of vectors\n",
        "index = faiss.IndexFlatL2(d)\n",
        "xb = np.random.random((nb, d)).astype('float32')\n",
        "index.add(xb)\n",
        "faiss.write_index(index, \"codebert_embeddings.index\")\n",
        "\n",
        "# Create dummy code snippets\n",
        "code_snippets = [\n",
        "    \"def greet(name):\\\\n  print(f'Hello, {name}!')\",\n",
        "    \"for i in range(5):\\\\n  print(i)\",\n",
        "    \"data = {'a': 1, 'b': 2}\\\\nprint(data['a'])\",\n",
        "    \"class MyClass:\\\\n  def __init__(self, value):\\\\n    self.value = value\",\n",
        "    \"result = 10 + 20\\\\nprint(result)\",\n",
        "    \"if x > 0:\\\\n  print('Positive')\",\n",
        "    \"def calculate_sum(a, b):\\\\n  return a + b\",\n",
        "    \"my_list = [1, 2, 3]\\\\nprint(len(my_list))\",\n",
        "    \"import os\\\\nprint(os.getcwd())\",\n",
        "    \"try:\\\\n  x = 1 / 0\\\\nexcept ZeroDivisionError:\\\\n  print('Cannot divide by zero')\"\n",
        "]\n",
        "with open(\"code_snippets.json\", \"w\") as f:\n",
        "    json.dump(code_snippets, f)\n",
        "\n",
        "print(\"Dummy 'codebert_embeddings.index' and 'code_snippets.json' created.\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy 'codebert_embeddings.index' and 'code_snippets.json' created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding function (CodeBERT)\n",
        "def get_embedding(text):\n",
        "    inputs = cb_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = cb_model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "\n",
        "# Search code\n",
        "def search(query, top_k=3):\n",
        "    query_emb = get_embedding(query).reshape(1, -1)\n",
        "    distances, indices = index.search(query_emb, top_k)\n",
        "    results = []\n",
        "    for rank, (idx, dist) in enumerate(zip(indices[0], distances[0]), 1):\n",
        "        results.append({\n",
        "            \"rank\": rank,\n",
        "            \"code\": code_snippets[idx],\n",
        "            \"distance\": float(dist)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Summarize code\n",
        "def summarize_code(code):\n",
        "    input_ids = t5_tokenizer(\"summarize: \" + code, return_tensors=\"pt\", truncation=True).input_ids\n",
        "    with torch.no_grad():\n",
        "        output_ids = t5_model.generate(input_ids, max_length=64, num_beams=4, early_stopping=True)\n",
        "    return t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# UI: Query input\n",
        "query_type = st.selectbox(\"Choose query type:\", [\"Natural Language\", \"Code Snippet\"])\n",
        "query = st.text_area(\"Enter your query:\", height=120)\n",
        "\n",
        "# Perform search\n",
        "if query:\n",
        "    st.info(f\"Searching using {query_type.lower()}...\")\n",
        "    results = search(query, top_k=3)\n",
        "    st.subheader(\"ðŸ”Ž Top Matching Code Snippets:\")\n",
        "    for result in results:\n",
        "        st.code(result[\"code\"], language=\"python\")\n",
        "        st.caption(f\"Rank #{result['rank']} â€¢ Distance: {result['distance']:.4f}\")\n",
        "\n",
        "    # Optional explanation\n",
        "    if query_type == \"Code Snippet\":\n",
        "        if st.button(\"ðŸ§  Explain This Code with CodeT5\"):\n",
        "            explanation = summarize_code(query)\n",
        "            st.subheader(\"ðŸ§  Code Explanation:\")\n",
        "            st.success(explanation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sdHiOF54Vh9",
        "outputId": "a72a5c1f-673c-4574-c930-7cfbfecd0d4b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-11 19:53:14.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.692 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.693 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.708 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.709 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.714 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 19:53:14.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok"
      ],
      "metadata": {
        "id": "YvEp9nGo4WAG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Get ngrok authtoken from Colab secrets\n",
        "ngrok_auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "if ngrok_auth_token:\n",
        "    ngrok.set_auth_token(ngrok_auth_token)\n",
        "else:\n",
        "    print(\"NGROK_AUTH_TOKEN not found in Colab secrets. Please add it.\")\n",
        "    # You might want to stop execution here if the token is essential\n",
        "    # exit()\n",
        "\n",
        "# Save the Streamlit code to a file\n",
        "streamlit_code = \"\"\"\n",
        "import streamlit as st\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "st.set_page_config(page_title=\"Code Search & Explanation\", layout=\"centered\")\n",
        "\n",
        "# Title\n",
        "st.title(\"ðŸ” Code Search & Explanation with CodeBERT + CodeT5\")\n",
        "st.markdown(\"Search your codebase using natural language or code snippets, and get explanations with CodeT5.\")\n",
        "\n",
        "# Load CodeBERT model and tokenizer\n",
        "@st.cache_resource\n",
        "def load_codebert():\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "# Load CodeT5 summarizer\n",
        "@st.cache_resource\n",
        "def load_codet5():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5-base\")\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "# Load FAISS index and code snippets\n",
        "# Assuming 'codebert_embeddings.index' and 'code_snippets.json' are already created\n",
        "try:\n",
        "    index = faiss.read_index(\"codebert_embeddings.index\")\n",
        "    with open(\"code_snippets.json\") as f:\n",
        "        code_snippets = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    st.error(\"Required data files (codebert_embeddings.index, code_snippets.json) not found. Please run the cell to create dummy files.\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# Embedding function (CodeBERT)\n",
        "def get_embedding(text):\n",
        "    inputs = cb_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = cb_model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "\n",
        "# Search code\n",
        "def search(query, top_k=3):\n",
        "    # Ensure models and index are loaded before use\n",
        "    global cb_tokenizer, cb_model, index, code_snippets\n",
        "    try:\n",
        "        cb_tokenizer, cb_model = load_codebert()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading CodeBERT model: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    try:\n",
        "        query_emb = get_embedding(query).reshape(1, -1)\n",
        "        distances, indices = index.search(query_emb, top_k)\n",
        "        results = []\n",
        "        for rank, (idx, dist) in enumerate(zip(indices[0], distances[0]), 1):\n",
        "            results.append({\n",
        "                \"rank\": rank,\n",
        "                \"code\": code_snippets[idx],\n",
        "                \"distance\": float(dist)\n",
        "            })\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during search: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "\n",
        "# Summarize code\n",
        "def summarize_code(code):\n",
        "    # Ensure CodeT5 model is loaded before use\n",
        "    global t5_tokenizer, t5_model\n",
        "    try:\n",
        "        t5_tokenizer, t5_model = load_codet5()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading CodeT5 model: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    try:\n",
        "        input_ids = t5_tokenizer(\"summarize: \" + code, return_tensors=\"pt\", truncation=True).input_ids\n",
        "        with torch.no_grad():\n",
        "            output_ids = t5_model.generate(input_ids, max_length=64, num_beams=4, early_stopping=True)\n",
        "        return t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during summarization: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "\n",
        "# UI: Query input\n",
        "query_type = st.selectbox(\"Choose query type:\", [\"Natural Language\", \"Code Snippet\"])\n",
        "query = st.text_area(\"Enter your query:\", height=120)\n",
        "\n",
        "# Perform search\n",
        "if query:\n",
        "    st.info(f\"Searching using {query_type.lower()}...\")\n",
        "    results = search(query, top_k=3)\n",
        "    st.subheader(\"ðŸ”Ž Top Matching Code Snippets:\")\n",
        "    for result in results:\n",
        "        st.code(result[\"code\"], language=\"python\")\n",
        "        st.caption(f\"Rank #{result['rank']} â€¢ Distance: {result['distance']:.4f}\")\n",
        "\n",
        "    # Optional explanation\n",
        "    if query_type == \"Code Snippet\":\n",
        "        if st.button(\"ðŸ§  Explain This Code with CodeT5\"):\n",
        "            explanation = summarize_code(query)\n",
        "            st.subheader(\"ðŸ§  Code Explanation:\")\n",
        "            st.success(explanation)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(streamlit_code)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(\"8501\")\n",
        "print(f\"âš¡ï¸ ngrok tunnel is live at {public_url}\")\n",
        "\n",
        "# Function to run streamlit in a separate thread\n",
        "def run_streamlit():\n",
        "    try:\n",
        "        # Use subprocess.Popen to keep the process running in the background\n",
        "        streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n",
        "        print(f\"Streamlit process launched with PID: {streamlit_process.pid}\")\n",
        "        streamlit_process.wait() # Wait for the process to finish if it exits\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: streamlit command not found. Make sure Streamlit is installed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while running Streamlit: {e}\")\n",
        "\n",
        "# Start streamlit in a new thread\n",
        "streamlit_thread = threading.Thread(target=run_streamlit)\n",
        "streamlit_thread.start()\n",
        "\n",
        "# Add a small delay to allow Streamlit to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Keep the main thread alive to prevent Colab from stopping the background process\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopping Streamlit and ngrok...\")\n",
        "    ngrok.disconnect(public_url)\n",
        "    streamlit_thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "QiNGRLMY4hoh",
        "outputId": "a76a31f8-6a00-4507-a1ac-a5cb49484241"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸ ngrok tunnel is live at NgrokTunnel: \"https://a74cfede3feb.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "Streamlit process launched with PID: 20434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-07-11T19:56:25+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-4a75082c-27d4-48e7-91dc-c420591cfcbc acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping Streamlit and ngrok...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokURLError",
          "evalue": "ngrok client exception, URLError: [Errno 111] Connection refused",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-35-4071858318.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1349\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http.client.connect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    963\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mExceptionGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"create_connection failed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    847\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    537\u001b[0m                                   '_open', req)\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 111] Connection refused>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPyngrokNgrokURLError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-35-4071858318.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stopping Streamlit and ngrok...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mstreamlit_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mdisconnect\u001b[0;34m(public_url, pyngrok_config)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpublic_url\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_current_tunnels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mget_tunnels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# One more check, if the given URL is still not in the list of tunnels, it is not active\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_tunnels\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0m_current_tunnels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     for tunnel in api_request(f\"{api_url}/api/tunnels\", method=\"GET\",\n\u001b[0m\u001b[1;32m    474\u001b[0m                               timeout=pyngrok_config.request_timeout)[\"tunnels\"]:\n\u001b[1;32m    475\u001b[0m         \u001b[0mngrok_tunnel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNgrokTunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtunnel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyngrok_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    650\u001b[0m                                     status_code, e.reason, e.headers, response_data)\n\u001b[1;32m    651\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPyngrokNgrokURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ngrok client exception, URLError: {e.reason}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPyngrokNgrokURLError\u001b[0m: ngrok client exception, URLError: [Errno 111] Connection refused"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMP_F3ti-xyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83dfc28b"
      },
      "source": [
        "# Task\n",
        "Explain the error in the provided Python code, fix it, and provide a step-by-step process for running the corrected code, including how to stop the server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10479210"
      },
      "source": [
        "## Ensure ngrok token is in colab secrets\n",
        "\n",
        "### Subtask:\n",
        "Verify that your ngrok authentication token is added to Colab's \"Secrets\" tab with the name `NGROK_AUTH_TOKEN`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b31afe0e"
      },
      "source": [
        "## Stop existing ngrok sessions\n",
        "\n",
        "### Subtask:\n",
        "Close any other active ngrok tunnels you might have running.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be429aae"
      },
      "source": [
        "## Run setup cells\n",
        "\n",
        "### Subtask:\n",
        "Execute the cells that install necessary libraries (`Streamlit`, `transformers`, `faiss-cpu`, `torch`, `pandas`, `pyngrok`) and create the dummy data files (`codebert_embeddings.index`, `code_snippets.json`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "883d2cfd"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to ensure all necessary libraries are installed. The provided notebook history shows cells that perform these installations. I will execute the cell that installs Streamlit, the cell that installs transformers, faiss-cpu, torch, and pandas, and the cell that installs pyngrok.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9dab2ea"
      },
      "source": [
        "!pip install Streamlit\n",
        "!pip install -q transformers faiss-cpu torch pandas\n",
        "!pip install -q pyngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "942daa61"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to create the dummy data files required by the Streamlit application. The provided notebook history includes a cell that generates a dummy FAISS index and code snippets JSON file. I will execute this cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6283d906",
        "outputId": "f96f8583-ba51-4e6a-8d11-3ae0380a7b6e"
      },
      "source": [
        "# Create dummy FAISS index and code snippets files for demonstration purposes\n",
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Create a dummy index\n",
        "d = 768  # Dimension of the embeddings (CodeBERT base)\n",
        "nb = 10  # Number of vectors\n",
        "index = faiss.IndexFlatL2(d)\n",
        "xb = np.random.random((nb, d)).astype('float32')\n",
        "index.add(xb)\n",
        "faiss.write_index(index, \"codebert_embeddings.index\")\n",
        "\n",
        "# Create dummy code snippets\n",
        "code_snippets = [\n",
        "    \"def greet(name):\\\\n  print(f'Hello, {name}!')\",\n",
        "    \"for i in range(5):\\\\n  print(i)\",\n",
        "    \"data = {'a': 1, 'b': 2}\\\\nprint(data['a'])\",\n",
        "    \"class MyClass:\\\\n  def __init__(self, value):\\\\n    self.value = value\",\n",
        "    \"result = 10 + 20\\\\nprint(result)\",\n",
        "    \"if x > 0:\\\\n  print('Positive')\",\n",
        "    \"def calculate_sum(a, b):\\\\n  return a + b\",\n",
        "    \"my_list = [1, 2, 3]\\\\nprint(len(my_list))\",\n",
        "    \"import os\\\\nprint(os.getcwd())\",\n",
        "    \"try:\\\\n  x = 1 / 0\\\\nexcept ZeroDivisionError:\\\\n  print('Cannot divide by zero')\"\n",
        "]\n",
        "with open(\"code_snippets.json\", \"w\") as f:\n",
        "    json.dump(code_snippets, f)\n",
        "\n",
        "print(\"Dummy 'codebert_embeddings.index' and 'code_snippets.json' created.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy 'codebert_embeddings.index' and 'code_snippets.json' created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eef38582"
      },
      "source": [
        "## Run the streamlit and ngrok cell\n",
        "\n",
        "### Subtask:\n",
        "Execute the cell that saves the Streamlit code to `app.py`, sets up the ngrok tunnel, and starts the Streamlit application in a background thread.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4489340"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires executing the cell that saves the Streamlit code to `app.py`, sets up the ngrok tunnel, and starts the Streamlit application. I will execute the provided code block to achieve this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "babae7cd",
        "outputId": "5b087911-1dcc-44b9-8563-662aa2011392"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Get ngrok authtoken from Colab secrets\n",
        "ngrok_auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "if ngrok_auth_token:\n",
        "    ngrok.set_auth_token(ngrok_auth_token)\n",
        "else:\n",
        "    print(\"NGROK_AUTH_TOKEN not found in Colab secrets. Please add it.\")\n",
        "    # You might want to stop execution here if the token is essential\n",
        "    # exit()\n",
        "\n",
        "# Save the Streamlit code to a file\n",
        "streamlit_code = \"\"\"\n",
        "import streamlit as st\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "st.set_page_config(page_title=\"Code Search & Explanation\", layout=\"centered\")\n",
        "\n",
        "# Title\n",
        "st.title(\"ðŸ” Code Search & Explanation with CodeBERT + CodeT5\")\n",
        "st.markdown(\"Search your codebase using natural language or code snippets, and get explanations with CodeT5.\")\n",
        "\n",
        "# Load CodeBERT model and tokenizer\n",
        "@st.cache_resource\n",
        "def load_codebert():\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "# Load CodeT5 summarizer\n",
        "@st.cache_resource\n",
        "def load_codet5():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5-base\")\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "# Load FAISS index and code snippets\n",
        "# Assuming 'codebert_embeddings.index' and 'code_snippets.json' are already created\n",
        "try:\n",
        "    index = faiss.read_index(\"codebert_embeddings.index\")\n",
        "    with open(\"code_snippets.json\") as f:\n",
        "        code_snippets = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    st.error(\"Required data files (codebert_embeddings.index, code_snippets.json) not found. Please run the cell to create dummy files.\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# Embedding function (CodeBERT)\n",
        "def get_embedding(text):\n",
        "    inputs = cb_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = cb_model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "\n",
        "# Search code\n",
        "def search(query, top_k=3):\n",
        "    # Ensure models and index are loaded before use\n",
        "    global cb_tokenizer, cb_model, index, code_snippets\n",
        "    try:\n",
        "        cb_tokenizer, cb_model = load_codebert()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading CodeBERT model: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    try:\n",
        "        query_emb = get_embedding(query).reshape(1, -1)\n",
        "        distances, indices = index.search(query_emb, top_k)\n",
        "        results = []\n",
        "        for rank, (idx, dist) in enumerate(zip(indices[0], distances[0]), 1):\n",
        "            results.append({\n",
        "                \"rank\": rank,\n",
        "                \"code\": code_snippets[idx],\n",
        "                \"distance\": float(dist)\n",
        "            })\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during search: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "\n",
        "# Summarize code\n",
        "def summarize_code(code):\n",
        "    # Ensure CodeT5 model is loaded before use\n",
        "    global t5_tokenizer, t5_model\n",
        "    try:\n",
        "        t5_tokenizer, t5_model = load_codet5()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading CodeT5 model: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    try:\n",
        "        input_ids = t5_tokenizer(\"summarize: \" + code, return_tensors=\"pt\", truncation=True).input_ids\n",
        "        with torch.no_grad():\n",
        "            output_ids = t5_model.generate(input_ids, max_length=64, num_beams=4, early_stopping=True)\n",
        "        return t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during summarization: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "\n",
        "# UI: Query input\n",
        "query_type = st.selectbox(\"Choose query type:\", [\"Natural Language\", \"Code Snippet\"])\n",
        "query = st.text_area(\"Enter your query:\", height=120)\n",
        "\n",
        "# Perform search\n",
        "if query:\n",
        "    st.info(f\"Searching using {query_type.lower()}...\")\n",
        "    results = search(query, top_k=3)\n",
        "    st.subheader(\"ðŸ”Ž Top Matching Code Snippets:\")\n",
        "    for result in results:\n",
        "        st.code(result[\"code\"], language=\"python\")\n",
        "        st.caption(f\"Rank #{result['rank']} â€¢ Distance: {result['distance']:.4f}\")\n",
        "\n",
        "    # Optional explanation\n",
        "    if query_type == \"Code Snippet\":\n",
        "        if st.button(\"ðŸ§  Explain This Code with CodeT5\"):\n",
        "            explanation = summarize_code(query)\n",
        "            st.subheader(\"ðŸ§  Code Explanation:\")\n",
        "            st.success(explanation)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(streamlit_code)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(\"8501\")\n",
        "print(f\"âš¡ï¸ ngrok tunnel is live at {public_url}\")\n",
        "\n",
        "# Function to run streamlit in a separate thread\n",
        "def run_streamlit():\n",
        "    try:\n",
        "        # Use subprocess.Popen to keep the process running in the background\n",
        "        streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n",
        "        print(f\"Streamlit process launched with PID: {streamlit_process.pid}\")\n",
        "        streamlit_process.wait() # Wait for the process to finish if it exits\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: streamlit command not found. Make sure Streamlit is installed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while running Streamlit: {e}\")\n",
        "\n",
        "# Start streamlit in a new thread\n",
        "streamlit_thread = threading.Thread(target=run_streamlit)\n",
        "streamlit_thread.start()\n",
        "\n",
        "# Add a small delay to allow Streamlit to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Keep the main thread alive to prevent Colab from stopping the background process\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopping Streamlit and ngrok...\")\n",
        "    ngrok.disconnect(public_url)\n",
        "    streamlit_thread.join()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸ ngrok tunnel is live at NgrokTunnel: \"https://84dba41ddba8.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "Streamlit process launched with PID: 23431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-07-11T20:02:05+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping Streamlit and ngrok...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ConnectionResetError",
          "evalue": "[Errno 104] Connection reset by peer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-40-4071858318.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-40-4071858318.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stopping Streamlit and ngrok...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mstreamlit_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mdisconnect\u001b[0;34m(public_url, pyngrok_config)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpublic_url\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_current_tunnels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mget_tunnels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# One more check, if the given URL is still not in the list of tunnels, it is not active\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_tunnels\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0m_current_tunnels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     for tunnel in api_request(f\"{api_url}/api/tunnels\", method=\"GET\",\n\u001b[0m\u001b[1;32m    474\u001b[0m                               timeout=pyngrok_config.request_timeout)[\"tunnels\"]:\n\u001b[1;32m    475\u001b[0m         \u001b[0mngrok_tunnel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNgrokTunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtunnel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyngrok_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    537\u001b[0m                                   '_open', req)\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81120715"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution of the cell failed with a KeyboardInterrupt and a ConnectionResetError during the cleanup phase (`ngrok.disconnect`). The core task of starting the Streamlit application and ngrok tunnel was likely attempted. Since the goal is to execute the cell to start the app and tunnel, I will re-execute the same code block. The errors encountered during the previous execution are related to interrupting the running process, not the initial setup and launch.\n",
        "\n"
      ]
    }
  ]
}